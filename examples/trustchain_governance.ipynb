{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/petro1eum/trust_chain/blob/main/examples/trustchain_governance.ipynb)\n\n",
                "# TrustChain Governance - Phase 13-15 Demo\n",
                "\n",
                "This notebook demonstrates:\n",
                "- **Phase 13**: Policy Layer (YAML rules, deny/allow/require)\n",
                "- **Phase 14**: Execution Graph (DAG analysis, fork detection)\n",
                "- **Phase 15**: MCP Security integration\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install TrustChain (required in Colab)\n",
                "!uv pip install -q trustchain"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TrustChain ready, key: 866f71ef-6cc7-41...\n"
                    ]
                }
            ],
            "source": [
                "from trustchain import ExecutionGraph, PolicyEngine, TrustChain, TrustChainConfig\n",
                "\n",
                "tc = TrustChain(TrustChainConfig(enable_nonce=False))\n",
                "print(f\"TrustChain ready, key: {tc.get_key_id()[:16]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 13: Policy Layer\n",
                "\n",
                "Runtime policy enforcement for AI governance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 2 policies\n",
                        "  - deny_dangerous_tools: deny\n",
                        "  - require_consent_for_pii: require\n"
                    ]
                }
            ],
            "source": [
                "# Define policies in YAML\n",
                "policy_yaml = \"\"\"\n",
                "policies:\n",
                "  - name: deny_dangerous_tools\n",
                "    if:\n",
                "      tool: delete_database\n",
                "    then:\n",
                "      deny:\n",
                "        message: Dangerous operations are blocked\n",
                "\n",
                "  - name: require_consent_for_pii\n",
                "    if:\n",
                "      tool: database_query\n",
                "      output.contains: [\"ssn\", \"passport\", \"credit_card\"]\n",
                "    then:\n",
                "      require:\n",
                "        - parent_tool: user_consent\n",
                "\"\"\"\n",
                "\n",
                "engine = PolicyEngine()\n",
                "engine.load_yaml(policy_yaml)\n",
                "print(f\"Loaded {len(engine.policies)} policies\")\n",
                "for p in engine.policies:\n",
                "    print(f\"  - {p.name}: {p.action.value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "delete_database: BLOCKED\n",
                        "  Reason: Dangerous operations are blocked\n"
                    ]
                }
            ],
            "source": [
                "# Test 1: Dangerous tool - BLOCKED\n",
                "dangerous_response = tc._signer.sign(\"delete_database\", {\"confirm\": True})\n",
                "passed, violations = engine.evaluate(dangerous_response)\n",
                "print(f\"delete_database: {'ALLOWED' if passed else 'BLOCKED'}\")\n",
                "if violations:\n",
                "    print(f\"  Reason: {violations[0]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PII query without consent: BLOCKED\n",
                        "  Reason: Policy 'require_consent_for_pii': requires parent tool 'user_consent' but no chain provided\n"
                    ]
                }
            ],
            "source": [
                "# Test 2: PII access without consent - BLOCKED\n",
                "pii_response = tc._signer.sign(\"database_query\", {\"result\": \"SSN: 123-45-6789\"})\n",
                "passed, violations = engine.evaluate(pii_response)\n",
                "print(f\"PII query without consent: {'ALLOWED' if passed else 'BLOCKED'}\")\n",
                "if violations:\n",
                "    print(f\"  Reason: {violations[0]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PII query WITH consent chain: ALLOWED\n"
                    ]
                }
            ],
            "source": [
                "# Test 3: PII access WITH consent chain - ALLOWED\n",
                "consent = tc._signer.sign(\"user_consent\", {\"granted\": True, \"scope\": \"pii_access\"})\n",
                "pii_with_consent = tc._signer.sign(\n",
                "    \"database_query\",\n",
                "    {\"result\": \"SSN: 123-45-6789\"},\n",
                "    parent_signature=consent.signature\n",
                ")\n",
                "\n",
                "passed, violations = engine.evaluate(pii_with_consent, chain=[consent, pii_with_consent])\n",
                "print(f\"PII query WITH consent chain: {'ALLOWED' if passed else 'BLOCKED'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 14: Execution Graph\n",
                "\n",
                "DAG analysis of agent execution for forensic analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Agent workflow: 5 steps\n"
                    ]
                }
            ],
            "source": [
                "# Simulate a complex agent workflow\n",
                "responses = []\n",
                "\n",
                "# Root\n",
                "start = tc._signer.sign(\"agent_init\", {\"session\": \"abc123\"})\n",
                "responses.append(start)\n",
                "\n",
                "# Research phase\n",
                "search = tc._signer.sign(\"web_search\", {\"query\": \"AI safety\"}, parent_signature=start.signature)\n",
                "responses.append(search)\n",
                "\n",
                "# Fork: two parallel analyses\n",
                "analyze_a = tc._signer.sign(\"analyze\", {\"aspect\": \"technical\"}, parent_signature=search.signature)\n",
                "analyze_b = tc._signer.sign(\"analyze\", {\"aspect\": \"ethical\"}, parent_signature=search.signature)\n",
                "responses.extend([analyze_a, analyze_b])\n",
                "\n",
                "# Merge: report from both analyses\n",
                "report = tc._signer.sign(\"generate_report\", {\"sources\": 2}, parent_signature=analyze_a.signature)\n",
                "responses.append(report)\n",
                "\n",
                "print(f\"Agent workflow: {len(responses)} steps\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Execution Graph Stats:\n",
                        "  total_nodes: 5\n",
                        "  total_roots: 1\n",
                        "  max_depth: 3\n",
                        "  unique_tools: 4\n",
                        "  forks: 1\n",
                        "  replays: 0\n",
                        "  orphans: 0\n"
                    ]
                }
            ],
            "source": [
                "# Build execution graph\n",
                "graph = ExecutionGraph.from_chain(responses)\n",
                "stats = graph.get_stats()\n",
                "\n",
                "print(\"Execution Graph Stats:\")\n",
                "for key, value in stats.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Forks detected: 1\n",
                        "  At 'web_search': 2 branches\n",
                        "    -> analyze\n",
                        "    -> analyze\n"
                    ]
                }
            ],
            "source": [
                "# Detect forks (where agent branched)\n",
                "forks = graph.detect_forks()\n",
                "print(f\"\\nForks detected: {len(forks)}\")\n",
                "for fork in forks:\n",
                "    print(f\"  At '{fork.parent_tool}': {len(fork.branches)} branches\")\n",
                "    for branch in fork.branches:\n",
                "        print(f\"    -> {branch.tool_id}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mermaid Diagram:\n",
                        "```mermaid\n",
                        "graph TD\n",
                        "    zkD1YSh4[\"agent_init\"]\n",
                        "    K+ipoRPo[\"web_search\"]\n",
                        "    xTFxdNnz[\"analyze\"]\n",
                        "    RlINh2kH[\"analyze\"]\n",
                        "    nYXGsPP9[\"generate_report\"]\n",
                        "    zkD1YSh4 --> K+ipoRPo\n",
                        "    K+ipoRPo --> xTFxdNnz\n",
                        "    K+ipoRPo --> RlINh2kH\n",
                        "    xTFxdNnz --> nYXGsPP9\n",
                        "    style zkD1YSh4 fill:#90EE90\n",
                        "    style K+ipoRPo fill:#FFD700\n",
                        "```\n"
                    ]
                }
            ],
            "source": [
                "# Visualize as Mermaid diagram\n",
                "mermaid = graph.export_mermaid()\n",
                "print(\"Mermaid Diagram:\")\n",
                "print(\"```mermaid\")\n",
                "print(mermaid)\n",
                "print(\"```\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Potential Replay Attacks: 1\n",
                        "  Tool 'payment': 3 identical calls\n"
                    ]
                }
            ],
            "source": [
                "# Detect potential replay attacks\n",
                "replay_test = [\n",
                "    tc._signer.sign(\"payment\", {\"amount\": 100}),\n",
                "    tc._signer.sign(\"payment\", {\"amount\": 100}),\n",
                "    tc._signer.sign(\"payment\", {\"amount\": 100}),\n",
                "]\n",
                "\n",
                "replay_graph = ExecutionGraph.from_chain(replay_test)\n",
                "replays = replay_graph.detect_replays()\n",
                "\n",
                "print(f\"Potential Replay Attacks: {len(replays)}\")\n",
                "for r in replays:\n",
                "    print(f\"  Tool '{r.tool_id}': {len(r.occurrences)} identical calls\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Execution Path to Report:\n",
                        "  1. agent_init\n",
                        "  2. web_search\n",
                        "  3. analyze\n",
                        "  4. generate_report\n"
                    ]
                }
            ],
            "source": [
                "# Get path from root to report\n",
                "path = graph.get_path(report.signature)\n",
                "print(\"\\nExecution Path to Report:\")\n",
                "for i, step in enumerate(path):\n",
                "    print(f\"  {i+1}. {step.tool_id}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Combined: Policy + Graph Analysis\n",
                "\n",
                "Complete AI governance pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Session Analysis:\n",
                        "  Total operations: 5\n",
                        "  Policy violations: 0\n",
                        "  Forks: 1\n",
                        "  Potential replays: 0\n",
                        "  Orphans: 0\n",
                        "\n",
                        "Status: COMPLIANT\n"
                    ]
                }
            ],
            "source": [
                "def analyze_agent_session(responses, policy_engine):\n",
                "    \"\"\"Complete session analysis with policy and graph checks.\"\"\"\n",
                "\n",
                "    # Build graph\n",
                "    graph = ExecutionGraph.from_chain(responses)\n",
                "\n",
                "    # Check policies\n",
                "    policy_violations = []\n",
                "    for resp in responses:\n",
                "        passed, violations = policy_engine.evaluate(resp, chain=responses)\n",
                "        if not passed:\n",
                "            policy_violations.extend(violations)\n",
                "\n",
                "    # Check graph anomalies\n",
                "    forks = graph.detect_forks()\n",
                "    replays = graph.detect_replays()\n",
                "    orphans = graph.detect_orphans()\n",
                "\n",
                "    return {\n",
                "        \"total_operations\": len(responses),\n",
                "        \"policy_violations\": policy_violations,\n",
                "        \"forks\": len(forks),\n",
                "        \"potential_replays\": len(replays),\n",
                "        \"orphaned_responses\": len(orphans),\n",
                "        \"graph\": graph\n",
                "    }\n",
                "\n",
                "# Analyze our session\n",
                "result = analyze_agent_session(responses, engine)\n",
                "\n",
                "print(\"Session Analysis:\")\n",
                "print(f\"  Total operations: {result['total_operations']}\")\n",
                "print(f\"  Policy violations: {len(result['policy_violations'])}\")\n",
                "print(f\"  Forks: {result['forks']}\")\n",
                "print(f\"  Potential replays: {result['potential_replays']}\")\n",
                "print(f\"  Orphans: {result['orphaned_responses']}\")\n",
                "print(f\"\\nStatus: {'COMPLIANT' if len(result['policy_violations']) == 0 else 'NON-COMPLIANT'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Use Cases\n",
                "\n",
                "- **SOC2/ISO Compliance**: Audit trail + policy enforcement\n",
                "- **AI Act (EU)**: Runtime governance for AI systems\n",
                "- **FinTech**: Prevent unauthorized transactions\n",
                "- **Healthcare (HIPAA)**: PII access control with consent chain\n",
                "- **Incident Response**: Fork/replay detection for forensics"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}