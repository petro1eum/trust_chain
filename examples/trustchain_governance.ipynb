{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrustChain Governance - Phase 13-15 Demo\n",
    "\n",
    "This notebook demonstrates:\n",
    "- **Phase 13**: Policy Layer (YAML rules, deny/allow/require)\n",
    "- **Phase 14**: Execution Graph (DAG analysis, fork detection)\n",
    "- **Phase 15**: MCP Security integration\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustchain import ExecutionGraph, PolicyEngine, TrustChain, TrustChainConfig\n",
    "\n",
    "tc = TrustChain(TrustChainConfig(enable_nonce=False))\n",
    "print(f\"TrustChain ready, key: {tc.get_key_id()[:16]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 13: Policy Layer\n",
    "\n",
    "Runtime policy enforcement for AI governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policies in YAML\n",
    "policy_yaml = \"\"\"\n",
    "policies:\n",
    "  - name: deny_dangerous_tools\n",
    "    if:\n",
    "      tool: delete_database\n",
    "    then:\n",
    "      deny:\n",
    "        message: Dangerous operations are blocked\n",
    "\n",
    "  - name: require_consent_for_pii\n",
    "    if:\n",
    "      tool: database_query\n",
    "      output.contains: [\"ssn\", \"passport\", \"credit_card\"]\n",
    "    then:\n",
    "      require:\n",
    "        - parent_tool: user_consent\n",
    "\"\"\"\n",
    "\n",
    "engine = PolicyEngine()\n",
    "engine.load_yaml(policy_yaml)\n",
    "print(f\"Loaded {len(engine.policies)} policies\")\n",
    "for p in engine.policies:\n",
    "    print(f\"  - {p.name}: {p.action.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Dangerous tool - BLOCKED\n",
    "dangerous_response = tc._signer.sign(\"delete_database\", {\"confirm\": True})\n",
    "passed, violations = engine.evaluate(dangerous_response)\n",
    "print(f\"delete_database: {'ALLOWED' if passed else 'BLOCKED'}\")\n",
    "if violations:\n",
    "    print(f\"  Reason: {violations[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: PII access without consent - BLOCKED\n",
    "pii_response = tc._signer.sign(\"database_query\", {\"result\": \"SSN: 123-45-6789\"})\n",
    "passed, violations = engine.evaluate(pii_response)\n",
    "print(f\"PII query without consent: {'ALLOWED' if passed else 'BLOCKED'}\")\n",
    "if violations:\n",
    "    print(f\"  Reason: {violations[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: PII access WITH consent chain - ALLOWED\n",
    "consent = tc._signer.sign(\"user_consent\", {\"granted\": True, \"scope\": \"pii_access\"})\n",
    "pii_with_consent = tc._signer.sign(\n",
    "    \"database_query\",\n",
    "    {\"result\": \"SSN: 123-45-6789\"},\n",
    "    parent_signature=consent.signature\n",
    ")\n",
    "\n",
    "passed, violations = engine.evaluate(pii_with_consent, chain=[consent, pii_with_consent])\n",
    "print(f\"PII query WITH consent chain: {'ALLOWED' if passed else 'BLOCKED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 14: Execution Graph\n",
    "\n",
    "DAG analysis of agent execution for forensic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a complex agent workflow\n",
    "responses = []\n",
    "\n",
    "# Root\n",
    "start = tc._signer.sign(\"agent_init\", {\"session\": \"abc123\"})\n",
    "responses.append(start)\n",
    "\n",
    "# Research phase\n",
    "search = tc._signer.sign(\"web_search\", {\"query\": \"AI safety\"}, parent_signature=start.signature)\n",
    "responses.append(search)\n",
    "\n",
    "# Fork: two parallel analyses\n",
    "analyze_a = tc._signer.sign(\"analyze\", {\"aspect\": \"technical\"}, parent_signature=search.signature)\n",
    "analyze_b = tc._signer.sign(\"analyze\", {\"aspect\": \"ethical\"}, parent_signature=search.signature)\n",
    "responses.extend([analyze_a, analyze_b])\n",
    "\n",
    "# Merge: report from both analyses\n",
    "report = tc._signer.sign(\"generate_report\", {\"sources\": 2}, parent_signature=analyze_a.signature)\n",
    "responses.append(report)\n",
    "\n",
    "print(f\"Agent workflow: {len(responses)} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build execution graph\n",
    "graph = ExecutionGraph.from_chain(responses)\n",
    "stats = graph.get_stats()\n",
    "\n",
    "print(\"Execution Graph Stats:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect forks (where agent branched)\n",
    "forks = graph.detect_forks()\n",
    "print(f\"\\nForks detected: {len(forks)}\")\n",
    "for fork in forks:\n",
    "    print(f\"  At '{fork.parent_tool}': {len(fork.branches)} branches\")\n",
    "    for branch in fork.branches:\n",
    "        print(f\"    -> {branch.tool_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as Mermaid diagram\n",
    "mermaid = graph.export_mermaid()\n",
    "print(\"Mermaid Diagram:\")\n",
    "print(\"```mermaid\")\n",
    "print(mermaid)\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect potential replay attacks\n",
    "replay_test = [\n",
    "    tc._signer.sign(\"payment\", {\"amount\": 100}),\n",
    "    tc._signer.sign(\"payment\", {\"amount\": 100}),\n",
    "    tc._signer.sign(\"payment\", {\"amount\": 100}),\n",
    "]\n",
    "\n",
    "replay_graph = ExecutionGraph.from_chain(replay_test)\n",
    "replays = replay_graph.detect_replays()\n",
    "\n",
    "print(f\"Potential Replay Attacks: {len(replays)}\")\n",
    "for r in replays:\n",
    "    print(f\"  Tool '{r.tool_id}': {len(r.occurrences)} identical calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path from root to report\n",
    "path = graph.get_path(report.signature)\n",
    "print(\"\\nExecution Path to Report:\")\n",
    "for i, step in enumerate(path):\n",
    "    print(f\"  {i+1}. {step.tool_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined: Policy + Graph Analysis\n",
    "\n",
    "Complete AI governance pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_agent_session(responses, policy_engine):\n",
    "    \"\"\"Complete session analysis with policy and graph checks.\"\"\"\n",
    "\n",
    "    # Build graph\n",
    "    graph = ExecutionGraph.from_chain(responses)\n",
    "\n",
    "    # Check policies\n",
    "    policy_violations = []\n",
    "    for resp in responses:\n",
    "        passed, violations = policy_engine.evaluate(resp, chain=responses)\n",
    "        if not passed:\n",
    "            policy_violations.extend(violations)\n",
    "\n",
    "    # Check graph anomalies\n",
    "    forks = graph.detect_forks()\n",
    "    replays = graph.detect_replays()\n",
    "    orphans = graph.detect_orphans()\n",
    "\n",
    "    return {\n",
    "        \"total_operations\": len(responses),\n",
    "        \"policy_violations\": policy_violations,\n",
    "        \"forks\": len(forks),\n",
    "        \"potential_replays\": len(replays),\n",
    "        \"orphaned_responses\": len(orphans),\n",
    "        \"graph\": graph\n",
    "    }\n",
    "\n",
    "# Analyze our session\n",
    "result = analyze_agent_session(responses, engine)\n",
    "\n",
    "print(\"Session Analysis:\")\n",
    "print(f\"  Total operations: {result['total_operations']}\")\n",
    "print(f\"  Policy violations: {len(result['policy_violations'])}\")\n",
    "print(f\"  Forks: {result['forks']}\")\n",
    "print(f\"  Potential replays: {result['potential_replays']}\")\n",
    "print(f\"  Orphans: {result['orphaned_responses']}\")\n",
    "print(f\"\\nStatus: {'COMPLIANT' if len(result['policy_violations']) == 0 else 'NON-COMPLIANT'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases\n",
    "\n",
    "- **SOC2/ISO Compliance**: Audit trail + policy enforcement\n",
    "- **AI Act (EU)**: Runtime governance for AI systems\n",
    "- **FinTech**: Prevent unauthorized transactions\n",
    "- **Healthcare (HIPAA)**: PII access control with consent chain\n",
    "- **Incident Response**: Fork/replay detection for forensics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
